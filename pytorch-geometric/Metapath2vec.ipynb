{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1799026a",
   "metadata": {},
   "source": [
    "[Metapath2vec paper](https://ericdongyx.github.io/papers/KDD17-dong-chawla-swami-metapath2vec.pdf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "90e4a8c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T14:29:03.972948Z",
     "start_time": "2021-06-07T14:29:03.956183Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Optional, Callable, List\n",
    "\n",
    "import os\n",
    "import os.path as osp\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import pandas\n",
    "from torch_sparse import coalesce, transpose\n",
    "from torch_geometric.data import (InMemoryDataset, Data, download_url,\n",
    "                                  extract_zip)\n",
    "\n",
    "import numpy as np\n",
    "from torch_geometric.datasets import AMiner\n",
    "from torch_geometric.nn import MetaPath2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbba5889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get author labels\n",
    "path = osp.join('net_aminer/')\n",
    "author = pandas.read_csv(path+'id_author.txt', sep='\\t', names=['idx', 'name'],\n",
    "                                 index_col=1)\n",
    "path = osp.join('label/googlescholar.8area.author.label.txt')\n",
    "df = pandas.read_csv(path, sep=' ', names=['name', 'y'])\n",
    "df = df.join(author, on='name')\n",
    "author_y = torch.from_numpy(df['y'].values) - 1\n",
    "author_y_index = torch.from_numpy(df['idx'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a61054e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T14:41:41.755586Z",
     "start_time": "2021-06-07T14:41:41.147173Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "googlescholar.8area.author.label.txt  googlescholar.8area.venue.label.txt\r\n"
     ]
    }
   ],
   "source": [
    "!ls label/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "07f28dbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T14:49:49.104228Z",
     "start_time": "2021-06-07T14:49:49.082431Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get venue labels.\n",
    "path = osp.join('net_aminer/')\n",
    "venue = pandas.read_csv(path+'id_conf.txt', sep='\\t', names=['idx', 'name'],\n",
    "                                index_col=1)\n",
    "path = osp.join('label/googlescholar.8area.venue.label.txt')\n",
    "df = pandas.read_csv(path, sep=' ', names=['name', 'y'])\n",
    "df = df.join(venue, on='name')\n",
    "                        \n",
    "venue_y = torch.from_numpy(df['y'].values) - 1\n",
    "venue_y_index = torch.from_numpy(df['idx'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "accbf372",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T14:42:56.224557Z",
     "start_time": "2021-06-07T14:42:52.079511Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get paper <-> author connectivity\n",
    "path = osp.join('net_aminer/paper_author.txt')\n",
    "paper_author = pandas.read_csv(path, sep='\\t', header=None)\n",
    "paper_author = torch.from_numpy(paper_author.values)\n",
    "paper_author = paper_author.t().contiguous() # t 가 무슨 함수인지 아직도 의문.\n",
    "M, N = int(paper_author[0].max() + 1), int(paper_author[1].max() + 1)\n",
    "paper_author, _ = coalesce(paper_author, None, M, N)\n",
    "author_paper, _ = transpose(paper_author, None, M, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d42156",
   "metadata": {},
   "source": [
    "_coalesce function_\n",
    "\n",
    "\n",
    "torch_sparse.coalesce(index, value, m, n, op=\"add\") -> (torch.LongTensor, torch.Tensor)\n",
    "\n",
    "Row-wise sorts index and removes duplicate entries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df2eb27c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T14:47:22.464230Z",
     "start_time": "2021-06-07T14:47:22.438049Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 1, 2],\n",
      "        [1, 0, 1, 0]])\n",
      "tensor([[6., 8.],\n",
      "        [7., 9.],\n",
      "        [3., 4.],\n",
      "        [5., 6.]])\n"
     ]
    }
   ],
   "source": [
    "# example\n",
    "index = torch.tensor([[1, 0, 1, 0, 2, 1],\n",
    "                     [0, 1, 1, 1, 0, 0]])\n",
    "value = torch.Tensor([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]])\n",
    "\n",
    "index, value = coalesce(index, value, m=3, n=2)\n",
    "\n",
    "print(index)\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2527ee9e",
   "metadata": {},
   "source": [
    "_transpose function_\n",
    "\n",
    "torch_sparse.transpose(index, value, m, n) -> (torch.LongTensor, torch.Tensor)\n",
    "\n",
    "Transposes dimensions 0 and 1 of a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56c753cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T14:48:21.451370Z",
     "start_time": "2021-06-07T14:48:21.439962Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 1, 1],\n",
      "        [1, 2, 0, 1]])\n",
      "tensor([[7., 9.],\n",
      "        [5., 6.],\n",
      "        [6., 8.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "# example \n",
    "index = torch.tensor([[1, 0, 1, 0, 2, 1],\n",
    "                      [0, 1, 1, 1, 0, 0]])\n",
    "value = torch.Tensor([[1, 2], [2, 3], [3, 4], [4, 5], [5, 6], [6, 7]])\n",
    "\n",
    "index, value = transpose(index, value, 3, 2)\n",
    "\n",
    "print(index)\n",
    "print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0d2e323b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T14:49:23.864452Z",
     "start_time": "2021-06-07T14:49:22.890787Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get paper<->venue connectivity\n",
    "path = osp.join('net_aminer/paper_conf.txt')\n",
    "paper_venue = pandas.read_csv(path, sep='\\t', header=None)\n",
    "paper_venue = torch.from_numpy(paper_venue.values)\n",
    "paper_venue = paper_venue.t().contiguous()\n",
    "M, N = int(paper_venue[0].max() + 1), int(paper_venue[1].max() + 1)\n",
    "paper_venue, _ = coalesce(paper_venue, None, M, N)\n",
    "venue_paper, _ = transpose(paper_venue, None, M, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "300da0d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T14:49:52.374006Z",
     "start_time": "2021-06-07T14:49:52.359397Z"
    }
   },
   "outputs": [],
   "source": [
    "data = Data(\n",
    "            edge_index_dict={\n",
    "                ('paper', 'written by', 'author'): paper_author,\n",
    "                ('author', 'wrote', 'paper'): author_paper,\n",
    "                ('paper', 'published in', 'venue'): paper_venue,\n",
    "                ('venue', 'published', 'paper'): venue_paper,\n",
    "            },\n",
    "            y_dict={\n",
    "                'author': author_y,\n",
    "                'venue': venue_y,\n",
    "            },\n",
    "            y_index_dict={\n",
    "                'author': author_y_index,\n",
    "                'venue': venue_y_index,\n",
    "            },\n",
    "            num_nodes_dict={\n",
    "                'paper': int(paper_author[0].max()) + 1,\n",
    "                'author': author.shape[0],\n",
    "                'venue': venue.shape[0],\n",
    "            },\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "370f478f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T14:57:38.682212Z",
     "start_time": "2021-06-07T14:57:38.670105Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(\n",
       "  edge_index_dict={\n",
       "    ('paper', 'written by', 'author')=[2, 9323605],\n",
       "    ('author', 'wrote', 'paper')=[2, 9323605],\n",
       "    ('paper', 'published in', 'venue')=[2, 3194405],\n",
       "    ('venue', 'published', 'paper')=[2, 3194405]\n",
       "  },\n",
       "  num_nodes_dict={\n",
       "    paper=3194405,\n",
       "    author=1693531,\n",
       "    venue=3883\n",
       "  },\n",
       "  y_dict={\n",
       "    author=[246678],\n",
       "    venue=[134]\n",
       "  },\n",
       "  y_index_dict={\n",
       "    author=[246678],\n",
       "    venue=[134]\n",
       "  }\n",
       ")"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc8655dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T14:21:51.352859Z",
     "start_time": "2021-06-07T14:21:51.338307Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Class MetaPath2vec(\\nedge_index_dict,\\nembedding_dim,\\nmetapath,\\nwalk_length,\\ncontext_size,\\nwalks_pernode,\\nnum_negative_samples,\\nnum_nodes_dict,\\nsparse)\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Class MetaPath2vec(\n",
    "edge_index_dict,\n",
    "embedding_dim,\n",
    "metapath,\n",
    "walk_length,\n",
    "context_size,\n",
    "walks_pernode,\n",
    "num_negative_samples,\n",
    "num_nodes_dict,\n",
    "sparse)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624aeb11",
   "metadata": {},
   "source": [
    "Metapath2vec\n",
    "\n",
    "\n",
    "- Given a specific Schema P\n",
    "\n",
    "\n",
    "스키마 p 를 manually building 해주어야함.\n",
    "\n",
    "- Extract random meta path from the input graph\n",
    "\n",
    "\n",
    "random walk 를 heterogeneous 하게 적용했다고 생각함.\n",
    "\n",
    "\n",
    "- Use the skip-gram model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "27baf415",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T14:58:56.167946Z",
     "start_time": "2021-06-07T14:58:56.164400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\npath = osp.join('..', 'data', 'AMiner')\\ndataset = AMiner(path)\\ndata = dataset[0]\\n\""
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋을 불러옴\n",
    "'''\n",
    "path = osp.join('..', 'data', 'AMiner')\n",
    "dataset = AMiner(path)\n",
    "data = dataset[0]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ff2d06d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:00:03.555136Z",
     "start_time": "2021-06-07T15:00:03.547381Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "tensor([[      0,       1,       2,  ..., 3194404, 3194404, 3194404],\n",
      "        [      0,       1,       2,  ...,    4393,   21681,  317436]])\n"
     ]
    }
   ],
   "source": [
    "print(type(data.edge_index_dict))\n",
    "print(data.edge_index_dict[('paper', 'written by', 'author')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d943c909",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:14:37.272378Z",
     "start_time": "2021-06-07T15:14:37.267603Z"
    }
   },
   "outputs": [],
   "source": [
    "# cpu -> GPU\n",
    "#device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "36b4576a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:14:50.371872Z",
     "start_time": "2021-06-07T15:14:38.553983Z"
    }
   },
   "outputs": [],
   "source": [
    "# modeling\n",
    "\n",
    "metapath = [\n",
    "    ('author', 'wrote', 'paper'),\n",
    "    ('paper', 'published in', 'venue'),\n",
    "    ('venue', 'published', 'paper'),\n",
    "    ('paper', 'written by', 'author'),\n",
    "]\n",
    "\n",
    "model = MetaPath2Vec(data.edge_index_dict,\n",
    "                    embedding_dim=128,\n",
    "                    metapath=metapath,\n",
    "                    context_size=3,\n",
    "                    walks_per_node=3,\n",
    "                    walk_length=5,\n",
    "                    num_negative_samples=1,\n",
    "                    sparse=True\n",
    "                    ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "de6a3fa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:14:50.376924Z",
     "start_time": "2021-06-07T15:14:50.373845Z"
    }
   },
   "outputs": [],
   "source": [
    "# loader\n",
    "loader = model.loader(batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ef9ccfb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:14:51.051056Z",
     "start_time": "2021-06-07T15:14:50.380330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 torch.Size([384, 3]) torch.Size([384, 3])\n",
      "1 torch.Size([384, 3]) torch.Size([384, 3])\n",
      "2 torch.Size([384, 3]) torch.Size([384, 3])\n",
      "3 torch.Size([384, 3]) torch.Size([384, 3])\n",
      "4 torch.Size([384, 3]) torch.Size([384, 3])\n",
      "5 torch.Size([384, 3]) torch.Size([384, 3])\n",
      "6 torch.Size([384, 3]) torch.Size([384, 3])\n",
      "7 torch.Size([384, 3]) torch.Size([384, 3])\n",
      "8 torch.Size([384, 3]) torch.Size([384, 3])\n",
      "9 torch.Size([384, 3]) torch.Size([384, 3])\n"
     ]
    }
   ],
   "source": [
    "for idx, (pos_rw, neg_rw) in enumerate(loader):\n",
    "    if idx == 10: break\n",
    "    print(idx, pos_rw.shape, neg_rw.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "66d125bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:14:51.059498Z",
     "start_time": "2021-06-07T15:14:51.053844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1489937, 4185789, 4890570]) tensor([1489937, 4138251, 4890223])\n"
     ]
    }
   ],
   "source": [
    "print(pos_rw[0], neg_rw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "db4d5530",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:14:51.070205Z",
     "start_time": "2021-06-07T15:14:51.061498Z"
    }
   },
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "2d97fef7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:14:51.077766Z",
     "start_time": "2021-06-07T15:14:51.072060Z"
    }
   },
   "outputs": [],
   "source": [
    "# Inizialize optimizer\n",
    "optimizer = torch.optim.SparseAdam(list(model.parameters()), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "17a6dc85",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:14:51.101489Z",
     "start_time": "2021-06-07T15:14:51.082727Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(epoch, log_steps=500, eval_steps=1000):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    for i, (pos_rw, neg_rw) in enumerate(loader):\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.loss(pos_rw.to(device), neg_rw.to(device))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        if (i + 1) % log_steps == 0:\n",
    "            print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
    "                   f'Loss: {total_loss / log_steps:.4f}'))\n",
    "            total_loss = 0\n",
    "\n",
    "        if (i + 1) % eval_steps == 0:\n",
    "            acc = test()\n",
    "            print((f'Epoch: {epoch}, Step: {i + 1:05d}/{len(loader)}, '\n",
    "                   f'Acc: {acc:.4f}'))\n",
    "\n",
    "# Evaluation \n",
    "            \n",
    "@torch.no_grad()\n",
    "def test(train_ratio=0.1):\n",
    "    model.eval()\n",
    "\n",
    "    z = model('author', batch=data.y_index_dict['author'])\n",
    "    y = data.y_dict['author']\n",
    "    ## perm function 은 여기에서 처음 접하는거같음...docu 보니까 그냥 n-1 random permutation을 ouptut으로 주는 역할.\n",
    "    perm = torch.randperm(z.size(0))\n",
    "    train_perm = perm[:int(z.size(0) * train_ratio)]\n",
    "    test_perm = perm[int(z.size(0) * train_ratio):]\n",
    "\n",
    "    return model.test(z[train_perm], y[train_perm], z[test_perm],\n",
    "                      y[test_perm], max_iter=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "20117438",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:14:51.110680Z",
     "start_time": "2021-06-07T15:14:51.105173Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.randperm\\nargument\\nn, \\n*, \\ngenerator=None, \\nout=None, \\ndtype=torch.int64, \\nlayout=torch.strided, \\ndevice=None, \\nrequires_grad=False, \\npin_memory=False) → Tensor\\n\\n>>> torch.randperm(4)\\ntensor([2, 1, 0, 3])\\n'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''torch.randperm\n",
    "argument\n",
    "n, \n",
    "*, \n",
    "generator=None, \n",
    "out=None, \n",
    "dtype=torch.int64, \n",
    "layout=torch.strided, \n",
    "device=None, \n",
    "requires_grad=False, \n",
    "pin_memory=False) → Tensor\n",
    "\n",
    ">>> torch.randperm(4)\n",
    "tensor([2, 1, 0, 3])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "4a59b431",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-07T15:26:17.335778Z",
     "start_time": "2021-06-07T15:14:51.113404Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Step: 00500/52923, Loss: 9.7243\n",
      "Epoch: 1, Step: 01000/52923, Loss: 9.4063\n",
      "Epoch: 1, Step: 01000/52923, Acc: 0.2763\n",
      "Epoch: 1, Step: 01500/52923, Loss: 9.0478\n",
      "Epoch: 1, Step: 02000/52923, Loss: 8.7355\n",
      "Epoch: 1, Step: 02000/52923, Acc: 0.2768\n",
      "Epoch: 1, Step: 02500/52923, Loss: 8.4120\n",
      "Epoch: 1, Step: 03000/52923, Loss: 8.1381\n",
      "Epoch: 1, Step: 03000/52923, Acc: 0.2753\n",
      "Epoch: 1, Step: 03500/52923, Loss: 7.9349\n",
      "Epoch: 1, Step: 04000/52923, Loss: 7.7319\n",
      "Epoch: 1, Step: 04000/52923, Acc: 0.2737\n",
      "Epoch: 1, Step: 04500/52923, Loss: 7.5585\n",
      "Epoch: 1, Step: 05000/52923, Loss: 7.3996\n",
      "Epoch: 1, Step: 05000/52923, Acc: 0.2761\n",
      "Epoch: 1, Step: 05500/52923, Loss: 7.2330\n",
      "Epoch: 1, Step: 06000/52923, Loss: 7.0731\n",
      "Epoch: 1, Step: 06000/52923, Acc: 0.2756\n",
      "Epoch: 1, Step: 06500/52923, Loss: 6.9587\n",
      "Epoch: 1, Step: 07000/52923, Loss: 6.8318\n",
      "Epoch: 1, Step: 07000/52923, Acc: 0.2760\n",
      "Epoch: 1, Step: 07500/52923, Loss: 6.7207\n",
      "Epoch: 1, Step: 08000/52923, Loss: 6.6283\n",
      "Epoch: 1, Step: 08000/52923, Acc: 0.2755\n",
      "Epoch: 1, Step: 08500/52923, Loss: 6.5491\n",
      "Epoch: 1, Step: 09000/52923, Loss: 6.4206\n",
      "Epoch: 1, Step: 09000/52923, Acc: 0.2757\n",
      "Epoch: 1, Step: 09500/52923, Loss: 6.3594\n",
      "Epoch: 1, Step: 10000/52923, Loss: 6.2907\n",
      "Epoch: 1, Step: 10000/52923, Acc: 0.2772\n",
      "Epoch: 1, Step: 10500/52923, Loss: 6.2041\n",
      "Epoch: 1, Step: 11000/52923, Loss: 6.1314\n",
      "Epoch: 1, Step: 11000/52923, Acc: 0.2762\n",
      "Epoch: 1, Step: 11500/52923, Loss: 6.0810\n",
      "Epoch: 1, Step: 12000/52923, Loss: 6.0284\n",
      "Epoch: 1, Step: 12000/52923, Acc: 0.2773\n",
      "Epoch: 1, Step: 12500/52923, Loss: 5.9892\n",
      "Epoch: 1, Step: 13000/52923, Loss: 5.9236\n",
      "Epoch: 1, Step: 13000/52923, Acc: 0.2742\n",
      "Epoch: 1, Step: 13500/52923, Loss: 5.8751\n",
      "Epoch: 1, Step: 14000/52923, Loss: 5.8398\n",
      "Epoch: 1, Step: 14000/52923, Acc: 0.2766\n",
      "Epoch: 1, Step: 14500/52923, Loss: 5.7823\n",
      "Epoch: 1, Step: 15000/52923, Loss: 5.7545\n",
      "Epoch: 1, Step: 15000/52923, Acc: 0.2762\n",
      "Epoch: 1, Step: 15500/52923, Loss: 5.7185\n",
      "Epoch: 1, Step: 16000/52923, Loss: 5.6407\n",
      "Epoch: 1, Step: 16000/52923, Acc: 0.2749\n",
      "Epoch: 1, Step: 16500/52923, Loss: 5.6281\n",
      "Epoch: 1, Step: 17000/52923, Loss: 5.6123\n",
      "Epoch: 1, Step: 17000/52923, Acc: 0.2748\n",
      "Epoch: 1, Step: 17500/52923, Loss: 5.5614\n",
      "Epoch: 1, Step: 18000/52923, Loss: 5.5578\n",
      "Epoch: 1, Step: 18000/52923, Acc: 0.2766\n",
      "Epoch: 1, Step: 18500/52923, Loss: 5.5283\n",
      "Epoch: 1, Step: 19000/52923, Loss: 5.5099\n",
      "Epoch: 1, Step: 19000/52923, Acc: 0.2764\n",
      "Epoch: 1, Step: 19500/52923, Loss: 5.4799\n",
      "Epoch: 1, Step: 20000/52923, Loss: 5.4703\n",
      "Epoch: 1, Step: 20000/52923, Acc: 0.2749\n",
      "Epoch: 1, Step: 20500/52923, Loss: 5.4477\n",
      "Epoch: 1, Step: 21000/52923, Loss: 5.4187\n",
      "Epoch: 1, Step: 21000/52923, Acc: 0.2758\n",
      "Epoch: 1, Step: 21500/52923, Loss: 5.4051\n",
      "Epoch: 1, Step: 22000/52923, Loss: 5.3992\n",
      "Epoch: 1, Step: 22000/52923, Acc: 0.2745\n",
      "Epoch: 1, Step: 22500/52923, Loss: 5.3670\n",
      "Epoch: 1, Step: 23000/52923, Loss: 5.3465\n",
      "Epoch: 1, Step: 23000/52923, Acc: 0.2770\n",
      "Epoch: 1, Step: 23500/52923, Loss: 5.3371\n",
      "Epoch: 1, Step: 24000/52923, Loss: 5.3459\n",
      "Epoch: 1, Step: 24000/52923, Acc: 0.2753\n",
      "Epoch: 1, Step: 24500/52923, Loss: 5.3087\n",
      "Epoch: 1, Step: 25000/52923, Loss: 5.3003\n",
      "Epoch: 1, Step: 25000/52923, Acc: 0.2766\n",
      "Epoch: 1, Step: 25500/52923, Loss: 5.3004\n",
      "Epoch: 1, Step: 26000/52923, Loss: 5.2886\n",
      "Epoch: 1, Step: 26000/52923, Acc: 0.2755\n",
      "Epoch: 1, Step: 26500/52923, Loss: 5.3001\n",
      "Epoch: 1, Step: 27000/52923, Loss: 5.2654\n",
      "Epoch: 1, Step: 27000/52923, Acc: 0.2750\n",
      "Epoch: 1, Step: 27500/52923, Loss: 5.2780\n",
      "Epoch: 1, Step: 28000/52923, Loss: 5.2637\n",
      "Epoch: 1, Step: 28000/52923, Acc: 0.2743\n",
      "Epoch: 1, Step: 28500/52923, Loss: 5.2461\n",
      "Epoch: 1, Step: 29000/52923, Loss: 5.2180\n",
      "Epoch: 1, Step: 29000/52923, Acc: 0.2748\n",
      "Epoch: 1, Step: 29500/52923, Loss: 5.2208\n",
      "Epoch: 1, Step: 30000/52923, Loss: 5.2173\n",
      "Epoch: 1, Step: 30000/52923, Acc: 0.2764\n",
      "Epoch: 1, Step: 30500/52923, Loss: 5.2222\n",
      "Epoch: 1, Step: 31000/52923, Loss: 5.2105\n",
      "Epoch: 1, Step: 31000/52923, Acc: 0.2760\n",
      "Epoch: 1, Step: 31500/52923, Loss: 5.2022\n",
      "Epoch: 1, Step: 32000/52923, Loss: 5.2168\n",
      "Epoch: 1, Step: 32000/52923, Acc: 0.2758\n",
      "Epoch: 1, Step: 32500/52923, Loss: 5.2037\n",
      "Epoch: 1, Step: 33000/52923, Loss: 5.1587\n",
      "Epoch: 1, Step: 33000/52923, Acc: 0.2751\n",
      "Epoch: 1, Step: 33500/52923, Loss: 5.1668\n",
      "Epoch: 1, Step: 34000/52923, Loss: 5.1628\n",
      "Epoch: 1, Step: 34000/52923, Acc: 0.2757\n",
      "Epoch: 1, Step: 34500/52923, Loss: 5.1737\n",
      "Epoch: 1, Step: 35000/52923, Loss: 5.1487\n",
      "Epoch: 1, Step: 35000/52923, Acc: 0.2770\n",
      "Epoch: 1, Step: 35500/52923, Loss: 5.1362\n",
      "Epoch: 1, Step: 36000/52923, Loss: 5.1722\n",
      "Epoch: 1, Step: 36000/52923, Acc: 0.2766\n",
      "Epoch: 1, Step: 36500/52923, Loss: 5.1395\n",
      "Epoch: 1, Step: 37000/52923, Loss: 5.1125\n",
      "Epoch: 1, Step: 37000/52923, Acc: 0.2766\n",
      "Epoch: 1, Step: 37500/52923, Loss: 5.1313\n",
      "Epoch: 1, Step: 38000/52923, Loss: 5.1137\n",
      "Epoch: 1, Step: 38000/52923, Acc: 0.2773\n",
      "Epoch: 1, Step: 38500/52923, Loss: 5.1042\n",
      "Epoch: 1, Step: 39000/52923, Loss: 5.0729\n",
      "Epoch: 1, Step: 39000/52923, Acc: 0.2744\n",
      "Epoch: 1, Step: 39500/52923, Loss: 5.0884\n",
      "Epoch: 1, Step: 40000/52923, Loss: 5.1078\n",
      "Epoch: 1, Step: 40000/52923, Acc: 0.2756\n",
      "Epoch: 1, Step: 40500/52923, Loss: 5.0864\n",
      "Epoch: 1, Step: 41000/52923, Loss: 5.0510\n",
      "Epoch: 1, Step: 41000/52923, Acc: 0.2768\n",
      "Epoch: 1, Step: 41500/52923, Loss: 5.0700\n",
      "Epoch: 1, Step: 42000/52923, Loss: 5.0727\n",
      "Epoch: 1, Step: 42000/52923, Acc: 0.2771\n",
      "Epoch: 1, Step: 42500/52923, Loss: 5.0401\n",
      "Epoch: 1, Step: 43000/52923, Loss: 5.0539\n",
      "Epoch: 1, Step: 43000/52923, Acc: 0.2753\n",
      "Epoch: 1, Step: 43500/52923, Loss: 5.0391\n",
      "Epoch: 1, Step: 44000/52923, Loss: 5.0217\n",
      "Epoch: 1, Step: 44000/52923, Acc: 0.2760\n",
      "Epoch: 1, Step: 44500/52923, Loss: 5.0282\n",
      "Epoch: 1, Step: 45000/52923, Loss: 5.0459\n",
      "Epoch: 1, Step: 45000/52923, Acc: 0.2763\n",
      "Epoch: 1, Step: 45500/52923, Loss: 5.0376\n",
      "Epoch: 1, Step: 46000/52923, Loss: 5.0153\n",
      "Epoch: 1, Step: 46000/52923, Acc: 0.2762\n",
      "Epoch: 1, Step: 46500/52923, Loss: 5.0096\n",
      "Epoch: 1, Step: 47000/52923, Loss: 4.9866\n",
      "Epoch: 1, Step: 47000/52923, Acc: 0.2758\n",
      "Epoch: 1, Step: 47500/52923, Loss: 4.9882\n",
      "Epoch: 1, Step: 48000/52923, Loss: 4.9971\n",
      "Epoch: 1, Step: 48000/52923, Acc: 0.2753\n",
      "Epoch: 1, Step: 48500/52923, Loss: 4.9707\n",
      "Epoch: 1, Step: 49000/52923, Loss: 4.9611\n",
      "Epoch: 1, Step: 49000/52923, Acc: 0.2768\n",
      "Epoch: 1, Step: 49500/52923, Loss: 4.9800\n",
      "Epoch: 1, Step: 50000/52923, Loss: 4.9587\n",
      "Epoch: 1, Step: 50000/52923, Acc: 0.2750\n",
      "Epoch: 1, Step: 50500/52923, Loss: 4.9564\n",
      "Epoch: 1, Step: 51000/52923, Loss: 4.9753\n",
      "Epoch: 1, Step: 51000/52923, Acc: 0.2768\n",
      "Epoch: 1, Step: 51500/52923, Loss: 4.9564\n",
      "Epoch: 1, Step: 52000/52923, Loss: 4.9546\n",
      "Epoch: 1, Step: 52000/52923, Acc: 0.2770\n",
      "Epoch: 1, Step: 52500/52923, Loss: 4.9443\n",
      "Epoch: 1, Accuracy: 0.2756349910590016\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1,2):\n",
    "    train(epoch)\n",
    "    acc = test()\n",
    "    print(f'Epoch: {epoch}, Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fea9777",
   "metadata": {},
   "source": [
    "batch size 를 128에서 32까지 줄여봤음에도 불구하고 gpu oom 이 발생함...\n",
    "부득이하게 device 를 cpu로 전환하였습니다..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
